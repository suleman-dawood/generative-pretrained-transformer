# generative-pretrained-transformer
The code trains and fine-tunes a Bigram-based language model using PyTorch. It processes a dataset, performs pretraining and fine-tuning on text data, and generates coherent text based on trained sequences. The pipeline includes dataset handling, tokenization, and model checkpoints for efficient training and recovery.
