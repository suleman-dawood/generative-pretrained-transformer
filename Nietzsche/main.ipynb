{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "637293\n",
      "ï»¿THUS SPAKE ZARATHUSTRA\n",
      "\n",
      "A BOOK FOR ALL AND NONE\n",
      "\n",
      "\n",
      "By Friedrich Nietzsche\n",
      "\n",
      "\n",
      "Translated By Thomas Com\n"
     ]
    }
   ],
   "source": [
    "# reading file\n",
    "with open(\"pg1998.txt\", 'r', encoding='utf-8') as file:\n",
    "    full_text = file.read()\n",
    "print(len(full_text))\n",
    "print(full_text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "characters = sorted(set(full_text))\n",
    "VOCAB_SIZE = len(characters)\n",
    "print(characters)\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded: [46, 53, 50, 39]\n",
      "Decoded: hola\n"
     ]
    }
   ],
   "source": [
    "# look into tiktoken\n",
    "\n",
    "# character-to-index mapping\n",
    "def create_mapping():\n",
    "    mapping = {}\n",
    "    for i, ch in enumerate(characters):\n",
    "        mapping[ch] = i\n",
    "    return mapping\n",
    "\n",
    "# encode a string using the mapping\n",
    "def encode(string, mapping):\n",
    "    encoded = []\n",
    "    for c in string:\n",
    "        encoded.append(mapping[c])\n",
    "    return encoded\n",
    "\n",
    "# reverse mapping for decoding\n",
    "def create_reverse_mapping(mapping):\n",
    "    reverse_mapping = {}\n",
    "    for ch, i in mapping.items():\n",
    "        reverse_mapping[i] = ch\n",
    "    return reverse_mapping\n",
    "\n",
    "# decode an encoded list back to the original string\n",
    "def decode(encoded, reverse_mapping):\n",
    "    decoded = []\n",
    "    for i in encoded:\n",
    "        decoded.append(reverse_mapping[i])\n",
    "    return ''.join(decoded)\n",
    "\n",
    "encoder_map = create_mapping()\n",
    "decoder_map = create_reverse_mapping(encoder_map)\n",
    "\n",
    "sample_string = encode(\"hola\", encoder_map)\n",
    "print(\"Encoded:\", sample_string)\n",
    "\n",
    "decoded_string = decode(sample_string, decoder_map)\n",
    "print(\"Decoded:\", decoded_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(1)\n",
    "data = torch.tensor(encode(full_text, encoder_map), dtype=torch.int64) # convert data into a tensor\n",
    "print(data[:100])\n",
    "\n",
    "split = int(0.8*len(data))\n",
    "training_set = data[:split] # split into training and validation set\n",
    "validation_set = data[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_size = 16 # the batch size to contain context in\n",
    "batch_size = 32 # how many sequences we are processing in each epoch\n",
    "\n",
    "x = training_set[:context_size]\n",
    "y = training_set[1:context_size+1] # y is the character after x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1, 47, 58,  1, 58, 53,  1, 39,  1, 46, 39, 54, 54, 63,  1, 47],\n",
      "        [57,  1, 55, 59, 43, 43, 52,  6,  1, 54, 39, 56, 58,  1, 53, 44],\n",
      "        [61, 43, 58,  1, 58, 46, 43, 47, 56,  1, 41, 46, 43, 43, 49, 57],\n",
      "        [50,  1, 46, 47, 51,  6,  1, 47, 52,  1, 46, 53, 54, 43,  1, 46],\n",
      "        [20, 43, 56, 43,  1, 41, 53, 51, 43, 57,  1, 30, 53, 51, 43, 53],\n",
      "        [63, 53, 59,  1, 52, 53, 61, 12,  0,  0, 35, 13, 30, 35, 21, 15],\n",
      "        [53, 44,  1, 58, 46, 43, 57, 43,  1, 51, 53, 39, 52, 57,  2,  0],\n",
      "        [ 1, 40, 43, 39, 56,  1, 47, 58,  1, 39, 57,  1, 63, 53, 59,  1],\n",
      "        [ 1, 46, 39, 54, 54, 47, 43, 56,  1, 50, 39, 52, 42, 57,  6,  0],\n",
      "        [53, 56,  1, 45, 52, 39, 56, 50, 47, 52, 45,  1, 57, 53, 56, 56],\n",
      "        [53, 42,  1, 61, 47, 50, 50,  0, 35, 46, 47, 41, 46,  1, 58, 47],\n",
      "        [39, 47, 42, 57,  1, 61, 53, 53, 47, 52, 45,  1, 39,  1, 51, 39],\n",
      "        [ 0, 24, 43, 57, 58,  1, 58, 46, 39, 58,  1, 58, 46, 63,  1, 50],\n",
      "        [46, 43, 56, 11,  1, 63, 43, 58,  1, 46, 43, 56, 43,  1, 46, 43],\n",
      "        [56, 47, 52, 45,  1, 58, 46, 63,  1, 50, 53, 57, 57,  1, 51, 39],\n",
      "        [57,  1, 61, 56, 53, 52, 45,  1, 58, 53,  1, 24, 39, 42, 63,  1],\n",
      "        [50, 47, 49, 43,  6,  0, 13, 52, 42,  1, 40, 53, 58, 46,  1, 54],\n",
      "        [59, 56, 57, 43, 50, 44,  0, 14, 63,  1, 41, 39, 50, 51, 52, 43],\n",
      "        [50, 42,  1, 54, 50, 43, 39, 57, 43, 10,  1,  5, 58, 47, 57,  1],\n",
      "        [47, 39, 50,  6,  1, 40, 43, 47, 52, 45,  1, 58, 46, 43, 52,  1],\n",
      "        [35, 21, 15, 23, 10,  0, 32, 46, 47, 57,  1, 57, 46, 39, 50, 50],\n",
      "        [43,  1, 46, 47, 51,  1, 44, 56, 53, 51,  1, 42, 39, 52, 45, 43],\n",
      "        [52, 43,  1, 43, 39, 56, 57,  0, 31, 59, 41, 46,  1, 46, 47, 42],\n",
      "        [ 1, 54, 47, 58, 63,  8,  1, 31, 47, 56,  6,  1, 40, 43,  1, 54],\n",
      "        [ 1, 57, 58, 56, 53, 49, 43, 57,  1, 39, 52, 42,  1, 46, 43, 56],\n",
      "        [53, 59, 50, 42,  1, 58, 46, 53, 59,  1, 61, 43, 56, 58,  1, 57],\n",
      "        [54, 53, 57, 58,  1, 39, 51, 39, 47, 52, 10,  0, 17, 42, 61, 39],\n",
      "        [ 1, 63, 53, 59, 56,  1, 42, 47, 57, 54, 53, 57, 47, 58, 47, 53],\n",
      "        [ 0, 13, 52, 42,  1, 51, 39, 52, 52, 43, 56, 50, 63,  1, 42, 47],\n",
      "        [59, 57, 58,  1, 63, 53, 59,  6,  1, 57, 47, 56,  8,  0,  0, 31],\n",
      "        [39, 51, 47, 58, 63,  1, 61, 47, 58, 46,  1, 58, 46, 43, 43, 10],\n",
      "        [53, 50, 42,  1, 42, 47, 57, 58, 56, 43, 57, 57,  5, 42,  6,  0]])\n",
      "tensor([[47, 58,  1, 58, 53,  1, 39,  1, 46, 39, 54, 54, 63,  1, 47, 57],\n",
      "        [ 1, 55, 59, 43, 43, 52,  6,  1, 54, 39, 56, 58,  1, 53, 44,  1],\n",
      "        [43, 58,  1, 58, 46, 43, 47, 56,  1, 41, 46, 43, 43, 49, 57,  0],\n",
      "        [ 1, 46, 47, 51,  6,  1, 47, 52,  1, 46, 53, 54, 43,  1, 46, 43],\n",
      "        [43, 56, 43,  1, 41, 53, 51, 43, 57,  1, 30, 53, 51, 43, 53,  6],\n",
      "        [53, 59,  1, 52, 53, 61, 12,  0,  0, 35, 13, 30, 35, 21, 15, 23],\n",
      "        [44,  1, 58, 46, 43, 57, 43,  1, 51, 53, 39, 52, 57,  2,  0, 32],\n",
      "        [40, 43, 39, 56,  1, 47, 58,  1, 39, 57,  1, 63, 53, 59,  1, 51],\n",
      "        [46, 39, 54, 54, 47, 43, 56,  1, 50, 39, 52, 42, 57,  6,  0, 32],\n",
      "        [56,  1, 45, 52, 39, 56, 50, 47, 52, 45,  1, 57, 53, 56, 56, 53],\n",
      "        [42,  1, 61, 47, 50, 50,  0, 35, 46, 47, 41, 46,  1, 58, 47, 56],\n",
      "        [47, 42, 57,  1, 61, 53, 53, 47, 52, 45,  1, 39,  1, 51, 39, 52],\n",
      "        [24, 43, 57, 58,  1, 58, 46, 39, 58,  1, 58, 46, 63,  1, 50, 53],\n",
      "        [43, 56, 11,  1, 63, 43, 58,  1, 46, 43, 56, 43,  1, 46, 43,  1],\n",
      "        [47, 52, 45,  1, 58, 46, 63,  1, 50, 53, 57, 57,  1, 51, 39, 49],\n",
      "        [ 1, 61, 56, 53, 52, 45,  1, 58, 53,  1, 24, 39, 42, 63,  1, 14],\n",
      "        [47, 49, 43,  6,  0, 13, 52, 42,  1, 40, 53, 58, 46,  1, 54, 56],\n",
      "        [56, 57, 43, 50, 44,  0, 14, 63,  1, 41, 39, 50, 51, 52, 43, 57],\n",
      "        [42,  1, 54, 50, 43, 39, 57, 43, 10,  1,  5, 58, 47, 57,  1, 45],\n",
      "        [39, 50,  6,  1, 40, 43, 47, 52, 45,  1, 58, 46, 43, 52,  1, 47],\n",
      "        [21, 15, 23, 10,  0, 32, 46, 47, 57,  1, 57, 46, 39, 50, 50,  1],\n",
      "        [ 1, 46, 47, 51,  1, 44, 56, 53, 51,  1, 42, 39, 52, 45, 43, 56],\n",
      "        [43,  1, 43, 39, 56, 57,  0, 31, 59, 41, 46,  1, 46, 47, 42, 43],\n",
      "        [54, 47, 58, 63,  8,  1, 31, 47, 56,  6,  1, 40, 43,  1, 54, 56],\n",
      "        [57, 58, 56, 53, 49, 43, 57,  1, 39, 52, 42,  1, 46, 43, 56, 43],\n",
      "        [59, 50, 42,  1, 58, 46, 53, 59,  1, 61, 43, 56, 58,  1, 57, 53],\n",
      "        [53, 57, 58,  1, 39, 51, 39, 47, 52, 10,  0, 17, 42, 61, 39, 56],\n",
      "        [63, 53, 59, 56,  1, 42, 47, 57, 54, 53, 57, 47, 58, 47, 53, 52],\n",
      "        [13, 52, 42,  1, 51, 39, 52, 52, 43, 56, 50, 63,  1, 42, 47, 57],\n",
      "        [57, 58,  1, 63, 53, 59,  6,  1, 57, 47, 56,  8,  0,  0, 31, 32],\n",
      "        [51, 47, 58, 63,  1, 61, 47, 58, 46,  1, 58, 46, 43, 43, 10,  0],\n",
      "        [50, 42,  1, 42, 47, 57, 58, 56, 43, 57, 57,  5, 42,  6,  0, 28]])\n",
      "torch.Size([32, 16])\n"
     ]
    }
   ],
   "source": [
    "def get_batch(split): # generate a small batch of data to process of inputs x and targets y\n",
    "\n",
    "    if split == 'train':\n",
    "        data = training_set\n",
    "    else:\n",
    "        data =  validation_set\n",
    "\n",
    "    # generate a random starting point and generate a batch from that\n",
    "    random_batch = torch.randint(len(data) - context_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+context_size] for i in random_batch])\n",
    "    y = torch.stack([data[i+1:i+context_size+1] for i in random_batch])\n",
    "\n",
    "    return x, y\n",
    "\n",
    "x_sample, y_sample = get_batch('train')\n",
    "print(x_sample)\n",
    "print(y_sample)\n",
    "print(x_sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_loss(model, val_iterations): # evaluates loss for both validation and trainiing sets\n",
    "    out = {}\n",
    "    model.eval() # set to validation mode\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(val_iterations) # initialize loss\n",
    "        for k in range(val_iterations): # val iterations is the training loss over x validation iterations\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean() # calculate loss mean\n",
    "    model.train() # set back to training\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 65]) tensor(4.6685, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional\n",
    "\n",
    "class BigramModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocabulary_size):\n",
    "        super().__init__()\n",
    "        self.embedding_table = nn.Embedding(vocabulary_size, vocabulary_size) # we create a 65 x 65 embedding table\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, index, targets=None):\n",
    "        logits = self.embedding_table(index) # logits are used to convert into a probability distribution for each token prediction\n",
    "\n",
    "        if targets==None:\n",
    "            loss = None\n",
    "        else:\n",
    "            logits = logits.view(-1, logits.size(-1))\n",
    "            targets = targets.view(-1) # logits and targets must be resized to be used with NNs\n",
    "            loss = self.loss_fn(logits, targets) # calculate difference between predicted value and target value\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, index, new_tokens): # generate likely tokens that come after selected index\n",
    "\n",
    "        for i in range(new_tokens):\n",
    "            logits, loss = self(index)\n",
    "            logits = logits[:, -1, :] # we only want the last token\n",
    "            probs = nn.functional.softmax(logits, dim=-1) # apply softmax to get probability distribution\n",
    "            next_index = torch.multinomial(probs, num_samples=1) # retrieve sample from the distribution\n",
    "            index = torch.cat((index, next_index), dim=1) # # append sample  to the full sequence\n",
    "        return index\n",
    "\n",
    "sample_model = BigramModel(VOCAB_SIZE)\n",
    "sample_logits, sample_loss = sample_model(x_sample, y_sample)\n",
    "\n",
    "print(sample_logits.shape, sample_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Main Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 4.6402, val loss 4.6277\n",
      "step 500: train loss 4.0626, val loss 4.0515\n",
      "step 1000: train loss 3.6047, val loss 3.6057\n",
      "step 1500: train loss 3.2662, val loss 3.2701\n",
      "step 2000: train loss 3.0192, val loss 3.0247\n",
      "step 2500: train loss 2.8379, val loss 2.8532\n",
      "step 3000: train loss 2.7188, val loss 2.7316\n",
      "step 3500: train loss 2.6349, val loss 2.6593\n",
      "step 4000: train loss 2.5851, val loss 2.6089\n",
      "step 4500: train loss 2.5484, val loss 2.5761\n",
      "step 5000: train loss 2.5229, val loss 2.5544\n",
      "step 5500: train loss 2.5108, val loss 2.5333\n",
      "step 6000: train loss 2.4952, val loss 2.5266\n",
      "step 6500: train loss 2.4842, val loss 2.5200\n",
      "step 7000: train loss 2.4780, val loss 2.5180\n",
      "step 7500: train loss 2.4730, val loss 2.5147\n",
      "step 8000: train loss 2.4665, val loss 2.5059\n",
      "step 8500: train loss 2.4689, val loss 2.5081\n",
      "step 9000: train loss 2.4597, val loss 2.5058\n",
      "step 9500: train loss 2.4614, val loss 2.5050\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(sample_model.parameters(), lr = 0.001)\n",
    "val_iterations = 500\n",
    "\n",
    "for epoch in range(10000):\n",
    "\n",
    "    # we compare training and validation loss every once in a while\n",
    "    if epoch % val_iterations == 0:\n",
    "        losses = estimate_loss(sample_model, val_iterations)\n",
    "        print(f\"step {epoch}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    x_sample, y_sample = get_batch(\"train\") # retrieve a batch randomly\n",
    "    # backpropogation step to compute gradients\n",
    "    logits, loss = sample_model(x_sample, y_sample)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Arond on h, cond wineoust mint.\n",
      "AUShewhombs. abe mboree t\n",
      "The fof ck\n",
      "CHe fete ishe at, You scod ais ave f D semonlalaprd sosserr thevetom; RINGoun Go asou m OMan, htithar the pe ss hotu swata'dr y incina fl Maiou y ttesot IVI ityo h tyofuss wherdr, plilitorint mee y\n",
      "W: cufoulicouer sh tithe Switief \n"
     ]
    }
   ],
   "source": [
    "initial = torch.zeros((1, 1), dtype=torch.long) # initial batch\n",
    "sample_generation = sample_model.generate(initial, new_tokens=300)[0].tolist() # generate the next 1000 tokens\n",
    "print(decode(sample_generation, decoder_map)) # predict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
